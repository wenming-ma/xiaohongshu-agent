"""
LangGraph ç³»ç»Ÿé…ç½®
æ”¯æŒå¤šæ¨¡å‹ã€æˆæœ¬ä¼˜åŒ–ã€ç¯å¢ƒå˜é‡ç®¡ç†
"""
import os
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# === é¡¹ç›®è·¯å¾„ ===
PROJECT_ROOT = Path(__file__).parent
POSTS_DIR = PROJECT_ROOT / "posts"
LEGACY_DIR = PROJECT_ROOT / "legacy"

# === API é…ç½® ===
# è‡ªå®šä¹‰ Anthropic API ç«¯ç‚¹ï¼ˆç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ¨¡å‹ï¼‰
ANTHROPIC_BASE_URL = os.getenv("ANTHROPIC_BASE_URL", "https://api.anthropic.com")
ANTHROPIC_AUTH_TOKEN = os.getenv("ANTHROPIC_AUTH_TOKEN")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY", ANTHROPIC_AUTH_TOKEN)

# OpenRouter é…ç½®ï¼ˆç”¨äºå›¾ç‰‡ç”Ÿæˆï¼‰
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_BASE_URL = os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1")
OPENROUTER_IMAGE_MODEL = os.getenv("OPENROUTER_IMAGE_MODEL", "openai/dall-e-3")
OPENROUTER_SITE_URL = os.getenv("OPENROUTER_SITE_URL", "")
OPENROUTER_SITE_NAME = os.getenv("OPENROUTER_SITE_NAME", "Xiaohongshu Agent")

# ä¼ ç»Ÿ API Keysï¼ˆå¯é€‰ï¼‰
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# === æ¨¡å‹é…ç½® ===
MODELS = {
    "claude": {
        "name": "claude-sonnet-4-5-20250929",
        "provider": "anthropic",
        "cost_per_1m_tokens": 3.0,
        "best_for": "å†…å®¹åˆ›ä½œã€é«˜è´¨é‡è¾“å‡º"
    },
    "gpt4": {
        "name": "gpt-4-turbo-2024-04-09",
        "provider": "openai",
        "cost_per_1m_tokens": 10.0,
        "best_for": "ç ”ç©¶ã€æ•°æ®å¤„ç†"
    },
    "gpt4o": {
        "name": "gpt-4o",
        "provider": "openai",
        "cost_per_1m_tokens": 5.0,
        "best_for": "å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬"
    },
    "gemini": {
        "name": "gemini-1.5-pro",
        "provider": "google",
        "cost_per_1m_tokens": 1.25,
        "best_for": "å›¾ç‰‡ç”Ÿæˆã€ä½æˆæœ¬"
    }
}

# === èŠ‚ç‚¹æ¨¡å‹æ˜ å°„ï¼ˆç»Ÿä¸€ä½¿ç”¨è‡ªå®šä¹‰ Anthropic ç«¯ç‚¹ï¼‰===
NODE_MODELS = {
    # Phase 1: åˆå§‹åŒ– - è½»é‡çº§
    "init_project": None,  # æ— éœ€LLM

    # Phase 2A: å¹¶è¡Œç ”ç©¶ - ä½¿ç”¨Claudeï¼ˆé€šè¿‡è‡ªå®šä¹‰ç«¯ç‚¹ï¼‰
    "research_xhs": "claude",
    "research_web": "claude",

    # Phase 2B: å†…å®¹åˆæˆ - ä½¿ç”¨Claude
    "synthesize": "claude",

    # Phase 3: å›¾ç‰‡ç”Ÿæˆ - ä½¿ç”¨Claudeï¼ˆæˆ–éœ€è¦å•ç‹¬é…ç½®ï¼‰
    "generate_images": "claude",

    # Phase 4: å‘å¸ƒ - æ— éœ€LLM
    "publish": None
}

# === å·¥ä½œæµé…ç½® ===
WORKFLOW_CONFIG = {
    # æœ€å¤§é‡è¯•æ¬¡æ•°
    "max_retries": 3,

    # è¶…æ—¶è®¾ç½®ï¼ˆç§’ï¼‰
    "node_timeout": 300,
    "total_timeout": 1800,

    # å¹¶è¡Œæ‰§è¡Œé…ç½®
    "parallel_research": True,

    # Checkpointing
    "enable_checkpointing": True,
    "checkpoint_dir": PROJECT_ROOT / ".checkpoints",

    # æ—¥å¿—
    "log_level": "INFO",
    "log_file": PROJECT_ROOT / "langgraph.log"
}

# === Xiaohongshu å¹³å°é…ç½® ===
XHS_CONFIG = {
    "publish_url": "https://creator.xiaohongshu.com/publish/publish",
    "login_url": "https://www.xiaohongshu.com/login",

    # å†…å®¹è§„èŒƒ
    "title_max_length": 20,
    "title_min_length": 10,
    "body_max_length": 1000,
    "body_min_length": 100,
    "hashtags_count": (3, 5),  # (min, max)
    "images_count": (1, 9),    # (min, max)

    # å‘å¸ƒè®¾ç½®
    "headless": False,  # æµè§ˆå™¨æ˜¯å¦æ— å¤´æ¨¡å¼
    "wait_after_publish": 5,  # å‘å¸ƒåç­‰å¾…ç§’æ•°
}

# === Web æœç´¢é…ç½® ===
WEB_SEARCH_CONFIG = {
    "platforms": {
        "xiaohongshu": {
            "search_url": "https://www.xiaohongshu.com/search_result",
            "enabled": True,
            "priority": 1
        },
        "zhihu": {
            "search_url": "https://www.zhihu.com/search",
            "enabled": True,
            "priority": 2
        },
        "weibo": {
            "search_url": "https://s.weibo.com/weibo",
            "enabled": True,
            "priority": 3
        },
        "baidu_tieba": {
            "search_url": "https://tieba.baidu.com/f/search/res",
            "enabled": True,
            "priority": 4
        }
    },

    # æœç´¢å‚æ•°
    "max_results_per_platform": 10,
    "search_timeout": 30,
    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
}

# === æˆæœ¬ä¼°ç®—å‡½æ•° ===
def estimate_cost(node_name: str, input_tokens: int, output_tokens: int) -> float:
    """ä¼°ç®—èŠ‚ç‚¹æ‰§è¡Œæˆæœ¬ï¼ˆç¾å…ƒï¼‰"""
    model_key = NODE_MODELS.get(node_name)
    if not model_key:
        return 0.0

    model_info = MODELS.get(model_key)
    if not model_info:
        return 0.0

    cost_per_1m = model_info["cost_per_1m_tokens"]
    total_tokens = input_tokens + output_tokens
    return (total_tokens / 1_000_000) * cost_per_1m


def get_model_for_node(node_name: str):
    """è·å–èŠ‚ç‚¹å¯¹åº”çš„æ¨¡å‹å®ä¾‹ï¼ˆç»Ÿä¸€ä½¿ç”¨è‡ªå®šä¹‰ Anthropic ç«¯ç‚¹ï¼‰"""
    from langchain_anthropic import ChatAnthropic
    from langchain_openai import ChatOpenAI
    from langchain_google_genai import ChatGoogleGenerativeAI

    model_key = NODE_MODELS.get(node_name)
    if not model_key:
        return None

    model_config = MODELS[model_key]
    provider = model_config["provider"]
    model_name = model_config["name"]

    if provider == "anthropic":
        # ä½¿ç”¨è‡ªå®šä¹‰ API ç«¯ç‚¹
        return ChatAnthropic(
            model=model_name,
            api_key=ANTHROPIC_API_KEY,
            base_url=ANTHROPIC_BASE_URL,
            temperature=0.7,
            max_tokens=4096
        )
    elif provider == "openai":
        # å¦‚æœä»éœ€ä½¿ç”¨ OpenAIï¼ˆå¦‚ DALL-E 3ï¼‰ï¼Œä¿ç•™åŸé…ç½®
        return ChatOpenAI(
            model=model_name,
            api_key=OPENAI_API_KEY,
            temperature=0.7
        )
    elif provider == "google":
        # å¦‚æœä»éœ€ä½¿ç”¨ Googleï¼Œä¿ç•™åŸé…ç½®
        return ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=GOOGLE_API_KEY,
            temperature=0.7
        )
    else:
        raise ValueError(f"Unsupported provider: {provider}")


# === ç¯å¢ƒæ£€æŸ¥ ===
def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®æ˜¯å¦å®Œæ•´"""
    import sys

    # è®¾ç½® Windows æ§åˆ¶å°ç¼–ç 
    if sys.platform == "win32":
        try:
            sys.stdout.reconfigure(encoding='utf-8')
        except:
            pass

    issues = []

    # æ£€æŸ¥è‡ªå®šä¹‰ Anthropic é…ç½®
    if not ANTHROPIC_BASE_URL:
        issues.append("Missing ANTHROPIC_BASE_URL")
    if not ANTHROPIC_AUTH_TOKEN and not ANTHROPIC_API_KEY:
        issues.append("Missing ANTHROPIC_AUTH_TOKEN or ANTHROPIC_API_KEY")

    # OpenAI å’Œ Google ç°åœ¨æ˜¯å¯é€‰çš„
    # if not OPENAI_API_KEY:
    #     issues.append("Missing OPENAI_API_KEY (optional)")
    # if not GOOGLE_API_KEY:
    #     issues.append("Missing GOOGLE_API_KEY (optional)")

    if issues:
        print("WARNING: Environment Issues:")
        for issue in issues:
            print(f"  - {issue}")
        print("\nPlease set missing configuration in .env file")
        return False

    print("OK: Environment check passed")
    print(f"Using Anthropic API endpoint: {ANTHROPIC_BASE_URL}")
    return True


if __name__ == "__main__":
    check_environment()
    print("\nğŸ“Š Model Configuration:")
    for node, model_key in NODE_MODELS.items():
        if model_key:
            model = MODELS[model_key]
            print(f"  {node:20s} â†’ {model['name']:30s} (${model['cost_per_1m_tokens']}/1M tokens)")
